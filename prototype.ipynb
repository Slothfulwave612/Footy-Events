{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from IPython.display import display\n",
    "from datetime import datetime, timedelta\n",
    "from apiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "scopes = ['https://www.googleapis.com/auth/calendar']\n",
    "\n",
    "month_name = {'January': 1, \n",
    "       'February': 2,\n",
    "       'March': 3,\n",
    "       'April': 4,\n",
    "       'May': 5,\n",
    "       'June': 6,\n",
    "       'July': 7,\n",
    "       'August': 8,\n",
    "       'September': 9,\n",
    "       'October': 10,\n",
    "       'November': 11, \n",
    "       'December': 12\n",
    "      }\n",
    "\n",
    "timezone = 'Asia/Kolkata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_struct(summary, desc, start_time, timezone):\n",
    "    start_time = datetime.strptime(start_time, \"%Y-%m-%dT%H:%M:%S\")\n",
    "    end_time = start_time + timedelta(hours=3)\n",
    "    \n",
    "    event = {\n",
    "      'summary': summary,\n",
    "      'description': desc,\n",
    "      'start': {\n",
    "        'dateTime': start_time.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "        'timeZone': timezone,\n",
    "      },\n",
    "      'end': {\n",
    "        'dateTime': end_time.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "        'timeZone': timezone,\n",
    "      },\n",
    "      'reminders': {\n",
    "        'useDefault': False,\n",
    "        'overrides': [\n",
    "          {'method': 'popup', 'minutes': 30},\n",
    "        ],\n",
    "      },\n",
    "    }\n",
    "    \n",
    "    return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_event(result, summary):\n",
    "    for i in range(0, len(result['items'])):\n",
    "        if result['items'][i]['summary'] == summary:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_event_struct(start_time):\n",
    "    start_time = datetime.strptime(start_time, \"%Y-%m-%dT%H:%M:%S\")\n",
    "    end_time = start_time + timedelta(hours=3)\n",
    "    \n",
    "    event = {\n",
    "         'start': {'dateTime': start_time.strftime(\"%Y-%m-%dT%H:%M:%S\"), 'timeZone': timezone},\n",
    "         'end': {'dateTime': end_time.strftime(\"%Y-%m-%dT%H:%M:%S\"), 'timeZone': timezone}\n",
    "            }\n",
    "    \n",
    "    return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'token.pkl' in os.listdir():\n",
    "    with open('token.pkl', 'rb') as f:\n",
    "        credentials = pickle.load(f)\n",
    "else:\n",
    "    flow = InstalledAppFlow.from_client_secrets_file('client_secret.json', scopes=scopes)\n",
    "    credentials = flow.run_console()\n",
    "    pickle.dump(credentials, open('token.pkl', 'wb'))\n",
    "\n",
    "service = build('calendar', 'v3', credentials=credentials)\n",
    "\n",
    "result = service.calendarList().list().execute()\n",
    "calendar_id = result['items'][0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_names():\n",
    "    with open('footy_teams.txt', 'r') as ofile:\n",
    "        team_content = ofile.readline()\n",
    "        ## reading the content from the file\n",
    "\n",
    "    team_content = team_content.split(',')\n",
    "    team_content = [x.strip() for x in team_content]\n",
    "    team_content = team_content[:-1]\n",
    "    ## splitting every team content into the list format\n",
    "    \n",
    "    return team_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_names():\n",
    "    with open('footy_comps.txt', 'r') as ofile:\n",
    "        comp_content = ofile.readline()\n",
    "    \n",
    "    comp_content = comp_content.split(';')\n",
    "    comp_content = [elem.strip() for elem in comp_content]\n",
    "    \n",
    "    return comp_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Google:\n",
    "    @classmethod\n",
    "    def search(self, search):\n",
    "        page = requests.get(\"http://www.google.de/search?q=\"+search)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "        links = soup.find_all(\"a\",href=re.compile(\"(?<=/url\\?q=)(htt.*://.*)\"))\n",
    "        urls = [re.split(\":(?=http)\",link[\"href\"].replace(\"/url?q=\",\"\"))[0] for link in links]\n",
    "        return [url for url in urls if 'webcache' not in url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_write(team_content, month_name, timezone):\n",
    "    for team in team_content:\n",
    "        print(f'For Team {team}')\n",
    "\n",
    "        search_term = f'{team} sky sports fixtures'\n",
    "\n",
    "        print('\\nGetting The Link of the website...\\n')\n",
    "\n",
    "        ## accessing the link of the website\n",
    "        website_link = Google.search(search_term)[0].split('&')[0]\n",
    "\n",
    "        print(f'\\nScrapping data for {team} from the website...\\n')\n",
    "        print(website_link)\n",
    "\n",
    "        ## scraping the content from the website\n",
    "        scrape_data = requests.get(website_link)\n",
    "        soup = BeautifulSoup(scrape_data.text, 'html.parser')\n",
    "\n",
    "        ## finding the div tag which contains all fixture's information\n",
    "        results = soup.find('div', attrs={'class': 'fixres__body'})\n",
    "        \n",
    "        ## scrapping fixuture's date, competition name, team names and timing of the fixtures\n",
    "        years = results.find_all('h3')\n",
    "        fix_date = results.find_all('h4')\n",
    "        comp_name = results.find_all('h5')\n",
    "        teams = results.find_all('span', attrs={'class': 'swap-text__target'})\n",
    "        timings = results.find_all('span', attrs={'class': 'matches__date'})\n",
    "\n",
    "        ## making a dict of all years\n",
    "        year_dict = {}\n",
    "\n",
    "        for year in years:\n",
    "            year_temp = year.text.split(' ')\n",
    "            year_dict[year_temp[0]] = year_temp[1]\n",
    "\n",
    "        ## making a list of all dates\n",
    "        date_text = []\n",
    "\n",
    "        for date in fix_date:\n",
    "            temp = date.text.split(' ')\n",
    "\n",
    "            date_final =''\n",
    "\n",
    "            for i in temp[1]:\n",
    "                if i.isdigit():\n",
    "                    date_final += i\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            year = year_dict[temp[2]]\n",
    "            month = month_name[temp[2]]\n",
    "\n",
    "            date_text.append(f'{date_final} {str(month)} {year}')\n",
    "\n",
    "        ## making a list of all competition names\n",
    "        comp_text = []\n",
    "\n",
    "        for comp in comp_name:\n",
    "            comp_text.append(comp.text)\n",
    "\n",
    "        ## making a list of match times\n",
    "        match_time = []\n",
    "\n",
    "        for time in timings:\n",
    "            match_time.append(time.text.strip())\n",
    "\n",
    "        final_time = []\n",
    "\n",
    "        for date_x, time_y in zip(date_text, match_time):\n",
    "            date_split = date_x.split(' ')\n",
    "            date_split = [int(elem) for elem in date_split]\n",
    "            time_split = time_y.split(':')\n",
    "            time_split = [int(elem) for elem in time_split]\n",
    "            temp_time = datetime(date_split[2], date_split[1], date_split[0], time_split[0], time_split[1], 0)\n",
    "            temp_time = temp_time + timedelta(hours=4)\n",
    "            final_time.append(temp_time)\n",
    "\n",
    "        ## making a dictionary that will contain all information\n",
    "\n",
    "        final_record = dict()\n",
    "        home_team = []\n",
    "        away_team = []\n",
    "\n",
    "        count = 1\n",
    "\n",
    "        for x_temp in teams:\n",
    "            if x_temp.text == '\\n\\n\\n\\n':\n",
    "                continue\n",
    "\n",
    "            elif count % 2 != 0:\n",
    "                home_team.append(x_temp.text)\n",
    "            else:\n",
    "                away_team.append(x_temp.text)\n",
    "            count += 1\n",
    "\n",
    "        for i in range(len(match_time)):\n",
    "            final_record['Date/Time'] = final_time\n",
    "            final_record['Competition'] = comp_text\n",
    "\n",
    "        final_record['Home_Team'] = home_team\n",
    "        final_record['Away_Team'] = away_team\n",
    "\n",
    "        print('\\nScrapped Successfully')\n",
    "\n",
    "        result = service.events().list(calendarId=calendar_id, timeZone=timezone, maxResults=9999).execute()\n",
    "        summary = []\n",
    "        desc = []\n",
    "        start_time = []\n",
    "        result_dict = {}\n",
    "\n",
    "        for item in range(len(result['items'])):\n",
    "            temp = result['items'][item]['summary'].split(' ')[-1]\n",
    "            if temp == '(Football)':\n",
    "                summary.append(result['items'][item]['summary'])\n",
    "                desc.append(result['items'][item]['description'])\n",
    "                date_temp = result['items'][item]['start']['dateTime']\n",
    "                start_time.append(date_temp)\n",
    "\n",
    "        result_dict['Summary'] = summary\n",
    "        result_dict['Description'] = desc\n",
    "        result_dict['start_time'] = start_time\n",
    "\n",
    "        for i in range(len(final_record['Home_Team'])):\n",
    "            temp_list = []\n",
    "\n",
    "            for index in final_record:\n",
    "                temp_list.append(final_record[index][i])\n",
    "\n",
    "            start_time = temp_list[0]\n",
    "            start_time = start_time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "            desc = temp_list[1]\n",
    "            summary = f'{temp_list[2]} vs {temp_list[3]} (Football)'\n",
    "            count = False\n",
    "            for j in range(len(result_dict['Summary'])):\n",
    "                if summary == result_dict['Summary'][j] and desc == result_dict['Description'][j]:\n",
    "                    if start_time != result_dict['start_time'][j][:-6]:\n",
    "                        print(f'Updating Event: {summary}')\n",
    "                        count = True\n",
    "                        index = update_event(result, summary)\n",
    "                        event_id = result['items'][index]['id']\n",
    "                        event = up_event_struct(start_time)\n",
    "                        up_e = service.events().patch(calendarId=calendar_id, eventId=event_id, body=event).execute()\n",
    "                        print('Event Updated Successfully')\n",
    "                        print()\n",
    "                        break\n",
    "                    else:\n",
    "                        count = True\n",
    "                        break\n",
    "            if count == False:\n",
    "                print(f'Adding Event: {summary}')\n",
    "                event = even_struct(summary, desc, start_time, timezone)\n",
    "                service.events().insert(calendarId=calendar_id, body=event).execute()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_teams, up_value = 'Man City, Juventus', False\n",
    "\n",
    "if up_value == True and len(up_teams) > 0:\n",
    "    orig_team = team_names()\n",
    "    team_content = up_teams.split(',')\n",
    "    team_content = [elem.strip() for elem in team_content]\n",
    "    team_content = [elem for elem in team_content if elem in orig_team]\n",
    "    scrape_write(team_content, month_name, timezone)\n",
    "else:\n",
    "    team_content = team_names()\n",
    "    scrape_write(team_content, month_name, timezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scrape_write_comp(comp_name, team_name, month_name, timezone, count_c=0):\n",
    "    for team in comp_name:\n",
    "        print(f'For Competition {team}')\n",
    "\n",
    "        search_term = f'{team} sky sports fixtures'\n",
    "\n",
    "        print('\\nGetting The Link of the website...\\n')\n",
    "\n",
    "        ## accessing the link of the website\n",
    "        website_link = Google.search(search_term)[0].split('&')[0]\n",
    "\n",
    "        print(f'\\nScrapping data for {team} from the website...\\n')\n",
    "        print(website_link)\n",
    "\n",
    "        ## scraping the content from the website\n",
    "        scrape_data = requests.get(website_link)\n",
    "        soup = BeautifulSoup(scrape_data.text, 'html.parser')\n",
    "\n",
    "        ## finding the div tag which contains all fixture's information\n",
    "        results = soup.find('div', attrs={'class': 'fixres__body'})\n",
    "        \n",
    "        ## scrapping fixuture's date, competition name, team names and timing of the fixtures\n",
    "        years = results.find_all('h3')\n",
    "        fix_date = results.find_all('h4')\n",
    "        teams = results.find_all('span', attrs={'class': 'swap-text__target'})\n",
    "        timings = results.find_all('span', attrs={'class': 'matches__date'})\n",
    "        \n",
    "        temp_team = team_name[count_c]\n",
    "        \n",
    "        results = str(results)\n",
    "        real_dates = []\n",
    "        \n",
    "        for i in range(len(fix_date)-1):\n",
    "            start = results.find(str(fix_date[i]))\n",
    "            end = results.find(str(fix_date[i+1]))\n",
    "            temp = results[start:end].count('<div class=\"fixres__item\">')\n",
    "            for j in range(temp):\n",
    "                real_dates.append(fix_date[i])\n",
    "        \n",
    "        start = results.find(fix_date[i+1].text)\n",
    "        temp = results[start:].count('<div class=\"fixres__item\">')\n",
    "        for j in range(temp):\n",
    "                real_dates.append(fix_date[i+1])\n",
    "        \n",
    "        ## making a dict of all years\n",
    "        year_dict = {}\n",
    "\n",
    "        for year in years:\n",
    "            year_temp = year.text.split(' ')\n",
    "            year_dict[year_temp[0]] = year_temp[1]\n",
    "\n",
    "        ## making a list of all dates\n",
    "        date_text = []\n",
    "\n",
    "        for date in real_dates:\n",
    "            temp = date.text.split(' ')\n",
    "\n",
    "            date_final =''\n",
    "\n",
    "            for i in temp[1]:\n",
    "                if i.isdigit():\n",
    "                    date_final += i\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            year = year_dict[temp[2]]\n",
    "            month = month_name[temp[2]]\n",
    "\n",
    "            date_text.append(f'{date_final} {str(month)} {year}')\n",
    "\n",
    "        ## making a list of match times\n",
    "        match_time = []\n",
    "\n",
    "        for time in timings:\n",
    "            match_time.append(time.text.strip())\n",
    "\n",
    "        temp_time_2 = []\n",
    "\n",
    "        for date_x, time_y in zip(date_text, match_time):\n",
    "            date_split = date_x.split(' ')\n",
    "            date_split = [int(elem) for elem in date_split]\n",
    "            time_split = time_y.split(':')\n",
    "            time_split = [int(elem) for elem in time_split]\n",
    "            temp_time = datetime(date_split[2], date_split[1], date_split[0], time_split[0], time_split[1], 0)\n",
    "            temp_time = temp_time + timedelta(hours=4)\n",
    "            temp_time_2.append(temp_time)\n",
    "\n",
    "        ## making a dictionary that will contain all information\n",
    "\n",
    "        final_record = dict()\n",
    "        home_team = []\n",
    "        away_team = []\n",
    "\n",
    "        count = 1\n",
    "\n",
    "        for x_temp in teams:\n",
    "            if x_temp.text == '\\n\\n\\n\\n':\n",
    "                continue\n",
    "\n",
    "            elif count % 2 != 0:\n",
    "                home_team.append(x_temp.text)\n",
    "            elif count % 2 == 0:\n",
    "                away_team.append(x_temp.text)\n",
    "            count += 1\n",
    "        \n",
    "        final_home = []\n",
    "        final_away = []\n",
    "        final_time = []\n",
    "        \n",
    "        for x, y, z in zip(home_team, away_team, temp_time_2):\n",
    "            if x in temp_team or y in temp_team:\n",
    "                final_home.append(x)\n",
    "                final_away.append(y)\n",
    "                final_time.append(z)\n",
    "\n",
    "        for i in range(len(match_time)):\n",
    "            final_record['Date/Time'] = final_time\n",
    "\n",
    "        final_record['Home_Team'] = final_home\n",
    "        final_record['Away_Team'] = final_away\n",
    "\n",
    "        print('\\nScrapped Successfully')\n",
    "        display(pd.DataFrame(final_record))\n",
    "        \n",
    "        count_c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Competition UCL\n",
      "\n",
      "Getting The Link of the website...\n",
      "\n",
      "\n",
      "Scrapping data for UCL from the website...\n",
      "\n",
      "https://www.skysports.com/champions-league-fixtures\n",
      "\n",
      "Scrapped Successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>Away_Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Atletico Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>Real Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Napoli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date/Time        Home_Team        Away_Team\n",
       "0 2020-03-12        Liverpool  Atletico Madrid\n",
       "1 2020-03-18  Manchester City      Real Madrid\n",
       "2 2020-03-19        Barcelona           Napoli"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Competition Premier League\n",
      "\n",
      "Getting The Link of the website...\n",
      "\n",
      "\n",
      "Scrapping data for Premier League from the website...\n",
      "\n",
      "https://www.skysports.com/premier-league-fixtures\n",
      "\n",
      "Scrapped Successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>Away_Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-11 23:30:00</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-14 19:00:00</td>\n",
       "      <td>Brighton and Hove Albion</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-17 00:00:00</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-21 21:30:00</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Crystal Palace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-04 19:00:00</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Norwich City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-04-05 20:30:00</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-04-12 20:30:00</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Aston Villa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-04-14 00:00:00</td>\n",
       "      <td>Wolverhampton Wanderers</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-04-18 21:30:00</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Leicester City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-04-21 00:00:00</td>\n",
       "      <td>Brighton and Hove Albion</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-04-25 16:30:00</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Burnley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-04-26 20:30:00</td>\n",
       "      <td>Tottenham Hotspur</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-05-02 19:00:00</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-05-09 19:00:00</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Arsenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-05-09 19:00:00</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Chelsea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-05-17 19:00:00</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Watford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-05-17 19:00:00</td>\n",
       "      <td>Newcastle United</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date/Time                 Home_Team       Away_Team\n",
       "0  2020-03-11 23:30:00           Manchester City         Arsenal\n",
       "1  2020-03-14 19:00:00  Brighton and Hove Albion         Arsenal\n",
       "2  2020-03-17 00:00:00                   Everton       Liverpool\n",
       "3  2020-03-21 21:30:00                 Liverpool  Crystal Palace\n",
       "4  2020-04-04 19:00:00                   Arsenal    Norwich City\n",
       "5  2020-04-05 20:30:00           Manchester City       Liverpool\n",
       "6  2020-04-12 20:30:00                 Liverpool     Aston Villa\n",
       "7  2020-04-14 00:00:00   Wolverhampton Wanderers         Arsenal\n",
       "8  2020-04-18 21:30:00                   Arsenal  Leicester City\n",
       "9  2020-04-21 00:00:00  Brighton and Hove Albion       Liverpool\n",
       "10 2020-04-25 16:30:00                 Liverpool         Burnley\n",
       "11 2020-04-26 20:30:00         Tottenham Hotspur         Arsenal\n",
       "12 2020-05-02 19:00:00                   Arsenal       Liverpool\n",
       "13 2020-05-09 19:00:00               Aston Villa         Arsenal\n",
       "14 2020-05-09 19:00:00                 Liverpool         Chelsea\n",
       "15 2020-05-17 19:00:00                   Arsenal         Watford\n",
       "16 2020-05-17 19:00:00          Newcastle United       Liverpool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "up_comp, up_value = '', False\n",
    "\n",
    "if up_value == True and len(up_comp) > 0:\n",
    "    ## update code\n",
    "    pass\n",
    "else:\n",
    "    comp_content = comp_names()\n",
    "    comp_name = [elem.split(':')[0] for elem in comp_content][:-1]\n",
    "    team_name = []\n",
    "    for team in comp_content[:-1]:\n",
    "        temp = team.split(':')[1]\n",
    "        team_name.append(temp.strip())    \n",
    "        \n",
    "    scrape_write_comp(comp_name, team_name, month_name, timezone)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
